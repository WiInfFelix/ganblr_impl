{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "from ganblr.models import GANBLR\n",
    "from data_utils import (\n",
    "    transfrom_dataframe_discrete,\n",
    "    preprocess_superstore,\n",
    "    preprocess_credit_risk,\n",
    "    preprocess_mushroom,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from metric_utils import get_trtr_metrics, get_sdv_metrics\n",
    "from datetime import datetime\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants\n",
    "\n",
    "EPOCHS = [10, 25, 50, 100, 150]\n",
    "K = [0, 1] \n",
    "\n",
    "overall_logfile = Path(f\"./new_logs/log_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\")\n",
    "\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/lib/cuda/\"\n",
    "\n",
    "timestamp_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open log\n",
    "with open(overall_logfile, \"w\") as f:\n",
    "    # write with ; as delimiter\n",
    "    f.write(\"Event;Model;Epochs;K;Dataset;Test;Metric;Value\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_datasets():\n",
    "    SUPERSTORE_PATH = Path(\"datasets/SampleSuperstore.csv\")\n",
    "    CREDIT_RISK_PATH = Path(\"datasets/credit_risk_dataset.csv\")\n",
    "    MUSHROOMS_PATH = Path(\"datasets/mushrooms.csv\")\n",
    "\n",
    "    SUPERSTORE_DF = pd.read_csv(SUPERSTORE_PATH)\n",
    "    CREDIT_RISK_DF = pd.read_csv(CREDIT_RISK_PATH)\n",
    "    MUSHROOMS_DF = pd.read_csv(MUSHROOMS_PATH)\n",
    "\n",
    "    SUPERSTORE_DF = preprocess_superstore(SUPERSTORE_DF)\n",
    "    CREDIT_RISK_DF = preprocess_credit_risk(CREDIT_RISK_DF)\n",
    "    MUSHROOMS_DF = preprocess_mushroom(MUSHROOMS_DF)\n",
    "\n",
    "    SUPERSTORE_DF_ENC, SUPERSTORE_ENCODERS = transfrom_dataframe_discrete(SUPERSTORE_DF)\n",
    "    CREDIT_RISK_DF_ENC, CREDIT_RISK_ENCODERS = transfrom_dataframe_discrete(CREDIT_RISK_DF)\n",
    "    MUSHROOMS_DF_ENC, MUSHROOMS_ENCODERS = transfrom_dataframe_discrete(MUSHROOMS_DF)\n",
    "\n",
    "    return (\n",
    "        SUPERSTORE_DF_ENC,\n",
    "        SUPERSTORE_ENCODERS,\n",
    "        CREDIT_RISK_DF_ENC,\n",
    "        CREDIT_RISK_ENCODERS,\n",
    "        MUSHROOMS_DF_ENC,\n",
    "        MUSHROOMS_ENCODERS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets():\n",
    "    X_super = SUPERSTORE_DF_ENC.drop(\"Profit\", axis=1)\n",
    "    y_super = SUPERSTORE_DF_ENC[\"Profit\"]\n",
    "\n",
    "    X_super_train, X_super_test, y_super_train, y_super_test = train_test_split(\n",
    "        X_super, y_super, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    X_credit = CREDIT_RISK_DF_ENC.drop(\"loan_status\", axis=1)\n",
    "    y_credit = CREDIT_RISK_DF_ENC[\"loan_status\"]\n",
    "\n",
    "    X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(\n",
    "        X_credit, y_credit, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    X_mushrooms = MUSHROOMS_DF_ENC.drop(\"class\", axis=1)\n",
    "    y_mushrooms = MUSHROOMS_DF_ENC[\"class\"]\n",
    "\n",
    "    (\n",
    "        X_mushrooms_train,\n",
    "        X_mushrooms_test,\n",
    "        y_mushrooms_train,\n",
    "        y_mushrooms_test,\n",
    "    ) = train_test_split(X_mushrooms, y_mushrooms, test_size=0.2, random_state=42)\n",
    "\n",
    "    return (\n",
    "        X_super_train,\n",
    "        X_super_test,\n",
    "        y_super_train,\n",
    "        y_super_test,\n",
    "        X_credit_train,\n",
    "        X_credit_test,\n",
    "        y_credit_train,\n",
    "        y_credit_test,\n",
    "        X_mushrooms_train,\n",
    "        X_mushrooms_test,\n",
    "        y_mushrooms_train,\n",
    "        y_mushrooms_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ganblr(\n",
    "    dataset_name,\n",
    "    X,\n",
    "    y,\n",
    "    df_enc,\n",
    "    encoders,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    epochs,\n",
    "    k,\n",
    "    timestamp_id,\n",
    "    overall_logfile,\n",
    "    i\n",
    "):\n",
    "\n",
    "    ganblr = GANBLR()\n",
    "    ganblr.fit(X_train, y_train, epochs=epochs, k=k)\n",
    "\n",
    "    synth_data = pd.DataFrame(\n",
    "        ganblr.sample(X.shape[0]),\n",
    "        columns=df_enc.columns,\n",
    "    )\n",
    "\n",
    "    ganblr = None\n",
    "\n",
    "    synth_data_clear = synth_data.copy()\n",
    "    for col in df_enc.columns:\n",
    "        synth_data_clear[col] = encoders[col].inverse_transform(\n",
    "            synth_data[[col]].astype(int)\n",
    "        )\n",
    "\n",
    "\n",
    "    synth_data_clear.to_csv(\n",
    "        f\"./synth_data/{timestamp_id}_ganblr_synth_data_{dataset_name}_{epochs}_{k}_{i}.csv\"\n",
    "    )\n",
    "\n",
    "    # get metrics\n",
    "    get_trtr_metrics(\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        synth_data,\n",
    "        dataset_name,\n",
    "        \"GANBLR\",\n",
    "        overall_logfile,\n",
    "        epochs,\n",
    "        k,\n",
    "    )\n",
    "\n",
    "    get_sdv_metrics(\n",
    "        real_data=df_enc,\n",
    "        synth_data=synth_data,\n",
    "        dataset_name=dataset_name,\n",
    "        model=\"GANBLR\",\n",
    "        overall_logfile=overall_logfile,\n",
    "        epochs=epochs,\n",
    "        k=k,\n",
    "        timestamp=timestamp_id,\n",
    "        i=i,\n",
    "    )\n",
    "\n",
    "    synth_data = None\n",
    "    synth_data_clear = None\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctgan_test(\n",
    "    dataset_name,\n",
    "    X,\n",
    "    y,\n",
    "    df_enc,\n",
    "    encoders,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    epochs,\n",
    "    k,\n",
    "    timestamp_id,\n",
    "    overall_logfile,\n",
    "    i\n",
    "):\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(data=df_enc)\n",
    "    ctgan = CTGANSynthesizer(metadata, epochs=epochs)\n",
    "    ctgan.fit(df_enc)\n",
    "\n",
    "    synth_data_ctgan = pd.DataFrame(\n",
    "        ctgan.sample(X.shape[0]),\n",
    "        columns=df_enc.columns,\n",
    "    )\n",
    "\n",
    "    ctgan = None\n",
    "\n",
    "    synth_data_ctgan_clear = synth_data_ctgan.copy()\n",
    "    for col in df_enc.columns:\n",
    "        synth_data_ctgan_clear[col] = encoders[col].inverse_transform(\n",
    "            synth_data_ctgan[[col]].astype(int)\n",
    "        )\n",
    "\n",
    "    synth_data_ctgan_clear.to_csv(\n",
    "        f\"./synth_data/{timestamp_id}_ctgan_synth_data_{dataset_name}_{epochs}_{k}_{i}.csv\"\n",
    "    )\n",
    "\n",
    "    get_trtr_metrics(\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        synth_data_ctgan,\n",
    "        dataset_name,\n",
    "        \"CTGAN\",\n",
    "        overall_logfile,\n",
    "        epochs,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    get_sdv_metrics(\n",
    "        real_data=df_enc,\n",
    "        synth_data=synth_data_ctgan,\n",
    "        dataset_name=dataset_name,\n",
    "        model=\"CTGAN\",\n",
    "        overall_logfile=overall_logfile,\n",
    "        epochs=epochs,\n",
    "        k=0,\n",
    "        timestamp=timestamp_id,\n",
    "        i=i,\n",
    "    )\n",
    "\n",
    "    synth_data_ctgan = None\n",
    "    synth_data_ctgan_clear = None\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(\n",
    "    dataset_name,\n",
    "    X,\n",
    "    y,\n",
    "    df_enc,\n",
    "    encoders,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    epochs,\n",
    "    K,\n",
    "    timestamp_id,\n",
    "    overall_logfile,\n",
    "):\n",
    "    for epoch in epochs:\n",
    "        for k in K:\n",
    "            for i in range(1, 4):\n",
    "                test_ganblr(\n",
    "                    dataset_name,\n",
    "                    X,\n",
    "                    y,\n",
    "                    df_enc,\n",
    "                    encoders,\n",
    "                    X_train,\n",
    "                    X_test,\n",
    "                    y_train,\n",
    "                    y_test,\n",
    "                    epoch,\n",
    "                    k,\n",
    "                    timestamp_id,\n",
    "                    overall_logfile,\n",
    "                    i\n",
    "                )\n",
    "                \n",
    "\n",
    "        for i in range(1, 4):\n",
    "            ctgan_test(\n",
    "                dataset_name,\n",
    "                X,\n",
    "                y,\n",
    "                df_enc,\n",
    "                encoders,\n",
    "                X_train,\n",
    "                X_test,\n",
    "                y_train,\n",
    "                y_test,\n",
    "                epoch,\n",
    "                0,\n",
    "                timestamp_id,\n",
    "                overall_logfile,\n",
    "                i\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERSTORE_DF_ENC, SUPERSTORE_ENCODERS, CREDIT_RISK_DF_ENC, CREDIT_RISK_ENCODERS, MUSHROOMS_DF_ENC, MUSHROOMS_ENCODERS = load_and_preprocess_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_super = SUPERSTORE_DF_ENC.drop(\"Profit\", axis=1)\n",
    "y_super = SUPERSTORE_DF_ENC[\"Profit\"]\n",
    "\n",
    "X_credit = CREDIT_RISK_DF_ENC.drop(\"loan_status\", axis=1)\n",
    "y_credit = CREDIT_RISK_DF_ENC[\"loan_status\"]\n",
    "\n",
    "X_mushrooms = MUSHROOMS_DF_ENC.drop(\"class\", axis=1)\n",
    "y_mushrooms = MUSHROOMS_DF_ENC[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_super_train, X_super_test, y_super_train, y_super_test, X_credit_train, X_credit_test, y_credit_train, y_credit_test, X_mushrooms_train, X_mushrooms_test, y_mushrooms_train, y_mushrooms_test = split_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(\n",
    "    dataset_name=\"superstore\",\n",
    "    X=X_super,\n",
    "    y=y_super,\n",
    "    df_enc=SUPERSTORE_DF_ENC,\n",
    "    encoders=SUPERSTORE_ENCODERS,\n",
    "    X_train=X_super_train,\n",
    "    X_test=X_super_test,\n",
    "    y_train=y_super_train,\n",
    "    y_test=y_super_test,\n",
    "    epochs=EPOCHS,\n",
    "    K=K,\n",
    "    timestamp_id=timestamp_id,\n",
    "    overall_logfile=overall_logfile,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(\n",
    "    dataset_name=\"credit_risk\",\n",
    "    X=X_credit,\n",
    "    y=y_credit,\n",
    "    df_enc=CREDIT_RISK_DF_ENC,\n",
    "    encoders=CREDIT_RISK_ENCODERS,\n",
    "    X_train=X_credit_train,\n",
    "    X_test=X_credit_test,\n",
    "    y_train=y_credit_train,\n",
    "    y_test=y_credit_test,\n",
    "    epochs=EPOCHS,\n",
    "    K=K,\n",
    "    timestamp_id=timestamp_id,\n",
    "    overall_logfile=overall_logfile,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(\n",
    "    dataset_name=\"mushrooms\",\n",
    "    X=X_mushrooms,\n",
    "    y=y_mushrooms,\n",
    "    df_enc=MUSHROOMS_DF_ENC,\n",
    "    encoders=MUSHROOMS_ENCODERS,\n",
    "    X_train=X_mushrooms_train,\n",
    "    X_test=X_mushrooms_test,\n",
    "    y_train=y_mushrooms_train,\n",
    "    y_test=y_mushrooms_test,\n",
    "    epochs=EPOCHS,\n",
    "    K=K,\n",
    "    timestamp_id=timestamp_id,\n",
    "    overall_logfile=overall_logfile,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
